{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPool2D, Flatten, Embedding, Concatenate, Dropout, Lambda, TimeDistributed, LSTM, GlobalAveragePooling2D, Reshape, DepthwiseConv2D, Permute, Activation, ConvLSTM2D\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import numpy as np                 \n",
    "\n",
    "#this combines all models and is able to add/remove \n",
    "def model_ccn(l2_dense=0.001, l2_conv=0.001, dropout=0.2, l2_emb=0.0001, num_sub=10, num_blocks=16540, dim=[1,26,26,17], emb_rem_index=0, feature_vector_dim=512):\n",
    "    #############################Inputs#########################################\n",
    "    #input_1: the electrodes data\n",
    "    #dim[1], dim[2], dim[3]: number of time points, number of frequencies, and number of electrodes\n",
    "    input1 = Input(shape=(dim[1], dim[2], dim[3]), name='Spectrograms') \n",
    "    \n",
    "    #MB is the minibatch size\n",
    "    MB =  tf.shape(input1)[0]\n",
    "    \n",
    "    #this converts (None, t, f, e) to (t, f, None, e), i.e. it makes spectrogram volumes (where the depth is the number of training examples), and the volumes are packed across e electrodes\n",
    "    input_new = tf.transpose(input1, perm=[1, 2, 0, 3])\n",
    "    #(required shape for depthwise convolution: (1, h, w, batch*numfilter))\n",
    "    spectograms_input = tf.reshape(input_new, [1, dim[1], dim[2], dim[3]*MB])\n",
    "    \n",
    "    #input 2: is a scalar, it is a subject index\n",
    "    sub_pk_input = Input(shape=[], name='Subject_pk')\n",
    "    #input 3: this is a scalar/dataset_emb \n",
    "    bl_pk_input = Input(shape=[], name='Block_pk')\n",
    "    \n",
    "    ###########################Embeddings#######################################\n",
    "    ##emb_rem_index: the embedding that are to be removed\n",
    "    #1: remove subject embedding\n",
    "    #2: time-frequency embedding\n",
    "    #3: remove electrode embedding    \n",
    "    #4: remove all the embeddings\n",
    "    #5: remove all the embeddings appended at the end (i.e., subject and dataset)\n",
    "    #else don't remove any embeddings\n",
    "    sub_emb = None\n",
    "    \n",
    "    kernel_tf = None\n",
    "    kernel_elec = None\n",
    "    x = None\n",
    "    \n",
    "    #1: subject Embedding\n",
    "    if emb_rem_index != 1 and emb_rem_index != 4 and emb_rem_index != 5:\n",
    "      #subject dimension = 5\n",
    "      sub_emb = Embedding(num_sub+1, 5, input_length = 1, name = 'Subject_Embedding')(sub_pk_input)\n",
    "\n",
    "    #4: electrode embedding\n",
    "    #Linear Combination of the channels/ subject wise to account for correcting the position of electrodes)\n",
    "    #Goal is to make a (1x1xe)@e filters\n",
    "    if emb_rem_index != 3 and emb_rem_index != 4:\n",
    "      kernel_elec = Embedding(num_blocks+1, dim[3]*dim[3], input_length=1, name='Electrode_Embedding')(bl_pk_input)\n",
    "      kernel_elec = tf.reshape(kernel_elec, [MB, 1, 1, dim[3], dim[3]], name = 'Reshape_kernel_elec')\n",
    "      kernel_elec = tf.transpose(kernel_elec, perm = [1, 2, 0, 3, 4])\n",
    "      kernel_elec = tf.reshape(kernel_elec, [1, 1, dim[3]*MB, dim[3]])\n",
    "\n",
    "\n",
    "      #Data Preprocessing: Embedding related\n",
    "      #Calculates group wise convolution using depth_wise convolution (as conv2D convolves across the entire mini batch) \n",
    "      x = None\n",
    "      for i in range(dim[3]):\n",
    "        #the depthwise equivalent is a sum of the filter of depth_wise kernel o/p\n",
    "        kern_temp = tf.reshape(kernel_elec[:, :, :, i], [1, 1, dim[3]*MB, 1])\n",
    "        y_temp = tf.nn.depthwise_conv2d(spectograms_input, filter = kern_temp, strides = [1,1,1,1], padding = 'SAME')\n",
    "        #sums across the filter dimension of the tensor (this this accounts for a single filter of a group wise convolution)\n",
    "        y_temp = tf.reshape(y_temp, [1, dim[1], dim[2], MB, dim[3]])\n",
    "        y_temp = tf.math.reduce_sum(y_temp, axis = -1, keepdims = True)\n",
    "        if x == None:\n",
    "          x = y_temp\n",
    "        else:\n",
    "          x = tf.concat([x, y_temp], axis=-1)\n",
    "    \n",
    "      x = tf.reshape(x, [1, dim[1], dim[2], dim[3]*MB])\n",
    "      #this is of the form (1, t, f, None), as required\n",
    "    else:\n",
    "      x = spectograms_input  \n",
    "    \n",
    "    #3: time-frequency embedding\n",
    "    #this is the high dimensional embedding for accounting variabilty in recordings    \n",
    "    #(3x3xe)@1: depthwise convolution\n",
    "    if emb_rem_index != 2 and emb_rem_index != 4: \n",
    "      kernel_tf = Embedding(num_blocks+1, 3*3*dim[3], input_length = 1, embeddings_regularizer=l2(l2_emb), name = 'Time_Frequency_Embedding')(bl_pk_input)\n",
    "      kernel_tf = tf.reshape(kernel_tf, [MB, 3, 3, dim[3], 1], name = 'Reshape_kernel_tf')\n",
    "      kernel_tf = tf.transpose(kernel_tf, perm = [1, 2, 0, 3, 4])\n",
    "      kernel_tf = tf.reshape(kernel_tf, [3, 3, dim[3]*MB, 1])\n",
    "\n",
    "      x = tf.nn.depthwise_conv2d(x, filter = kernel_tf, strides = [1,1,1,1], padding = 'SAME')\n",
    "      x = Activation('elu')(x)\n",
    "    \n",
    "    ##########################Common Network####################################\n",
    "    #reshaping for final computation    \n",
    "    x = tf.reshape(x, [dim[1], dim[2], MB, dim[3]])\n",
    "    x = tf.transpose(x, perm = [2, 0, 1, 3], name = 'after_all_preprocess')\n",
    "    \n",
    "    max_filter1 = (3, 2)\n",
    "    max_filter2 = (3, 2)\n",
    "    max_filter3 = (2, 2)\n",
    "\n",
    "\n",
    "    x = Conv2D(96, (7, 7), activation='elu', padding = 'same', kernel_regularizer=l2(l2_conv), name = 'CONV_1')(x)\n",
    "    x = MaxPool2D(max_filter1, name = 'MaxPool_1')(x)\n",
    "\n",
    "    x = Conv2D(64, (5, 5), activation='elu', padding = 'same', kernel_regularizer=l2(l2_conv), name = 'CONV_2')(x)\n",
    "    x = MaxPool2D(max_filter2, name = 'MaxPool_2')(x)\n",
    "    \n",
    "    x = Conv2D(32, (3, 3), activation='elu', padding = 'same', kernel_regularizer=l2(l2_conv), name = 'CONV_3')(x)\n",
    "    x = MaxPool2D(max_filter3, name = 'MaxPool_3')(x)\n",
    "    \n",
    "    x = Flatten(name = 'Flatten')(x)\n",
    "    x = Dropout(dropout, name = 'Dropout')(x)\n",
    "    x = Dense(40, activation ='elu', kernel_regularizer=l2(l2_dense), name = 'Dense')(x)    \n",
    "\n",
    "    #########################Final layers#######################################\n",
    "    x2 = None\n",
    "    #First append the subject embedding\n",
    "    if sub_emb == None:\n",
    "      x2 = x\n",
    "    else:\n",
    "      x2 = Concatenate(name = 'Concatenate')([x, sub_emb])\n",
    "    \n",
    "    #Classification\n",
    "    #output = Dense(1, activation ='softmax', name = 'Output')(x2)\n",
    "    output = Dense(feature_vector_dim, name = 'Output')(x2)\n",
    "    \n",
    "    return Model(inputs={\"input_1\": input1, \"input_2\": sub_pk_input, \"input_3\": bl_pk_input}, outputs=output)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 11:32:52.046232: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-03 11:32:52.233213: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-03 11:32:52.270737: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2025-01-03 11:32:52.270768: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2025-01-03 11:32:52.912677: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2025-01-03 11:32:52.912723: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2025-01-03 11:32:52.912726: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import h5py\n",
    "import os\n",
    "\n",
    "path_to_feature_vectors = \"/home/aditis/decodingEEG/DecodeEEG/data/feature_vectors/\"\n",
    "path_to_spectrograms = \"/home/aditis/decodingEEG/DecodeEEG/data/spectrograms/\"\n",
    "\n",
    "# Simulated data (replace with actual data)\n",
    "num_samples = 16540 * 4 * 10\n",
    "num_subjects = 10\n",
    "num_images_per_sub = 16540 * 4\n",
    "dim = [1, 26, 26, 17]  # Spectrogram input dimensions\n",
    "feature_vector_dim = 512  # Ground truth feature vector dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16540, 512)\n",
      "Spectrogram dataset shape: (16540, 4, 17, 26, 26) for subject: 1\n",
      "Spectrogram dataset shape: (16540, 4, 17, 26, 26) for subject: 2\n",
      "Spectrogram dataset shape: (16540, 4, 17, 26, 26) for subject: 3\n",
      "Spectrogram dataset shape: (16540, 4, 17, 26, 26) for subject: 4\n",
      "Spectrogram dataset shape: (16540, 4, 17, 26, 26) for subject: 5\n",
      "Spectrogram dataset shape: (16540, 4, 17, 26, 26) for subject: 6\n",
      "Spectrogram dataset shape: (16540, 4, 17, 26, 26) for subject: 7\n",
      "Spectrogram dataset shape: (16540, 4, 17, 26, 26) for subject: 8\n",
      "Spectrogram dataset shape: (16540, 4, 17, 26, 26) for subject: 9\n",
      "Spectrogram dataset shape: (16540, 4, 17, 26, 26) for subject: 10\n",
      "(661600, 512)\n"
     ]
    }
   ],
   "source": [
    "subject_ids = []\n",
    "block_ids = []\n",
    "specs = []\n",
    "feats = []\n",
    "\n",
    "# load all image vectors\n",
    "path_to_features = \"/home/aditis/decodingEEG/DecodeEEG/data/feature_vectors\"\n",
    "\n",
    "# Initialize an empty list to store the loaded arrays\n",
    "data = []\n",
    "\n",
    "classes = os.listdir(path_to_features+\"/training/\")\n",
    "\n",
    "for clas in classes:\n",
    "    feature_path  = path_to_features + \"/training/\" + clas\n",
    "    files = os.listdir(feature_path)\n",
    "    for file in files:\n",
    "        if file.endswith('.npy'):  # Ensure it's a .npy file\n",
    "            file_path = feature_path +\"/\"+ file\n",
    "            array = np.load(file_path)  # Load the .npy file\n",
    "\n",
    "            data.append(array)         # Append to the list\n",
    "# Convert the list of arrays into a matrix\n",
    "feature_matrix = np.vstack(data)  # Stack arrays vertically\n",
    "print(feature_matrix.shape)\n",
    "\n",
    "    \n",
    "# Convert the list of arrays into a matrix\n",
    "feature_matrix = np.vstack(data)  # Stack arrays vertically\n",
    "\n",
    "for i in range(num_subjects):\n",
    "    sub_ind = i+1\n",
    "    path_to_spec = \"/home/aditis/decodingEEG/DecodeEEG/data/spectrograms/sub-\" + \"{:02}\".format(sub_ind) + \"/\"\n",
    "    with h5py.File(path_to_spec+'spectrograms_train.h5', 'r') as f: \n",
    "        # Access the dataset\n",
    "        spectrograms = f['spectrograms']  # This is a reference to the dataset\n",
    "        print(f\"Spectrogram dataset shape: {spectrograms.shape} for subject: {sub_ind}\")  # Example: (No of images, No of trials, 17, 26, 26)\n",
    "\n",
    "        # Reshape the array\n",
    "        num_images, num_trials, depth, height, width = spectrograms.shape\n",
    "        for j in range(num_images):\n",
    "            block_ind = j\n",
    "            for k in range(num_trials):\n",
    "                subject_ids.append(sub_ind)\n",
    "                block_ids.append(block_ind)\n",
    "                feature_vector = feature_matrix[j,:]\n",
    "                spectrogram = spectrograms[j, k, :,:,:]\n",
    "                feats.append(feature_vector)\n",
    "                specs.append(spectrogram)\n",
    "\n",
    "print(np.vstack(feats).shape)\n",
    "print(np.array(specs).shape)               \n",
    "print(np.array(subject_ids).shape)\n",
    "print(np.array(block_ids).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "model = model_ccn(feature_vector_dim=feature_vector_dim)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    {\"input_1\":np.array(specs), \"input_2\": np.array(subject_ids), \"input_3\": np.array(block_ids)},\n",
    "    np.vstack(feats),\n",
    "    batch_size=32,\n",
    "    epochs=20,\n",
    "    validation_split=0.2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
